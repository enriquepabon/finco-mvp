'use client';

import { useState, useRef, useEffect, useCallback } from 'react';

/**
 * Hook para conversaciones bidireccionales por voz
 * Maneja Speech Recognition (entrada) y Speech Synthesis (salida)
 */

interface UseVoiceConversationProps {
  onUserSpeech: (transcript: string) => void;
  onConversationEnd?: () => void;
  autoSpeak?: boolean; // Si debe hablar automÃ¡ticamente las respuestas
  language?: string;
}

interface VoiceConversationState {
  isListening: boolean;
  isSpeaking: boolean;
  currentTranscript: string;
  error: string | null;
  isSupported: boolean;
}

// Type definitions para Web Speech API
interface SpeechRecognitionAlternative {
  transcript: string;
  confidence: number;
}

interface SpeechRecognitionResult {
  [index: number]: SpeechRecognitionAlternative;
  isFinal: boolean;
  length: number;
}

interface SpeechRecognitionResultList {
  [index: number]: SpeechRecognitionResult;
  length: number;
}

interface SpeechRecognitionEvent extends Event {
  resultIndex: number;
  results: SpeechRecognitionResultList;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  onstart: (() => void) | null;
  onresult: ((event: SpeechRecognitionEvent) => void) | null;
  onerror: ((event: SpeechRecognitionErrorEvent) => void) | null;
  onend: (() => void) | null;
  start(): void;
  stop(): void;
  abort(): void;
}

type SpeechRecognitionConstructor = new () => SpeechRecognition;

interface WindowWithSpeechRecognition extends Window {
  SpeechRecognition?: SpeechRecognitionConstructor;
  webkitSpeechRecognition?: SpeechRecognitionConstructor;
}

export function useVoiceConversation({
  onUserSpeech,
  onConversationEnd,
  autoSpeak = true,
  language = 'es-CO'
}: UseVoiceConversationProps) {
  
  const [state, setState] = useState<VoiceConversationState>(() => {
    // InicializaciÃ³n del estado con check de soporte
    if (typeof window === 'undefined') {
      return {
        isListening: false,
        isSpeaking: false,
        currentTranscript: '',
        error: null,
        isSupported: false
      };
    }

    const windowWithSpeech = window as WindowWithSpeechRecognition;
    const SpeechRecognition = windowWithSpeech.SpeechRecognition || windowWithSpeech.webkitSpeechRecognition;
    const SpeechSynthesis = window.speechSynthesis;
    const isSupported = !!(SpeechRecognition && SpeechSynthesis);

    return {
      isListening: false,
      isSpeaking: false,
      currentTranscript: '',
      error: null,
      isSupported
    };
  });

  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const synthesisRef = useRef<SpeechSynthesis | null>(null);
  const currentUtteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
  const voicesLoadedRef = useRef(false);
  
  // Refs para configuraciÃ³n (evita recrear callbacks)
  const autoSpeakRef = useRef(autoSpeak);
  const languageRef = useRef(language);
  
  // Actualizar refs cuando cambian los props
  useEffect(() => {
    autoSpeakRef.current = autoSpeak;
    languageRef.current = language;
  }, [autoSpeak, language]);

  // Inicializar Web Speech API
  useEffect(() => {
    if (typeof window === 'undefined') return;

    const windowWithSpeech = window as WindowWithSpeechRecognition;
    const SpeechRecognition = windowWithSpeech.SpeechRecognition || windowWithSpeech.webkitSpeechRecognition;
    const SpeechSynthesis = window.speechSynthesis;

    const isSupported = !!(SpeechRecognition && SpeechSynthesis);

    if (!isSupported) {
      console.warn('âš ï¸ Web Speech API no disponible en este navegador');
      return;
    }

    // Inicializar Speech Recognition
    recognitionRef.current = new SpeechRecognition();
    const recognition = recognitionRef.current;

    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = languageRef.current;
    recognition.maxAlternatives = 1;

    recognition.onstart = () => {
      console.log('ðŸŽ™ï¸ Escuchando...');
      setState(prev => ({ ...prev, isListening: true, error: null }));
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      let interimTranscript = '';
      let finalTranscript = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }

      // Actualizar transcripciÃ³n en tiempo real
      setState(prev => ({ 
        ...prev, 
        currentTranscript: finalTranscript || interimTranscript 
      }));

      // Si hay transcripciÃ³n final, enviarla
      if (finalTranscript.trim()) {
        console.log('âœ… TranscripciÃ³n final:', finalTranscript);
        onUserSpeech(finalTranscript.trim());
      }
    };

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.error('âŒ Error en reconocimiento de voz:', event.error);
      let errorMessage = 'Error de reconocimiento de voz';
      
      if (event.error === 'no-speech') {
        errorMessage = 'No se detectÃ³ voz. Intenta hablar mÃ¡s alto.';
      } else if (event.error === 'not-allowed') {
        errorMessage = 'Permisos de micrÃ³fono denegados. Por favor, permite el acceso al micrÃ³fono.';
      } else if (event.error === 'network') {
        errorMessage = 'Error de conexiÃ³n. Verifica tu internet o intenta recargar la pÃ¡gina.';
        // Auto-retry despuÃ©s de un momento
        setTimeout(() => {
          if (recognitionRef.current && state.isListening) {
            console.log('ðŸ”„ Reintentando reconocimiento de voz...');
            try {
              recognitionRef.current.start();
            } catch (e) {
              console.error('No se pudo reintentar:', e);
            }
          }
        }, 2000);
      } else if (event.error === 'aborted') {
        errorMessage = 'Reconocimiento cancelado.';
      } else if (event.error === 'audio-capture') {
        errorMessage = 'No se puede acceder al micrÃ³fono. Verifica que estÃ© conectado.';
      } else if (event.error === 'service-not-allowed') {
        errorMessage = 'Servicio de reconocimiento de voz no disponible en este navegador.';
      }
      
      setState(prev => ({ ...prev, error: errorMessage, isListening: false }));
    };

    recognition.onend = () => {
      console.log('ðŸ Reconocimiento finalizado');
      setState(prev => ({ ...prev, isListening: false }));
    };

    // Inicializar Speech Synthesis
    synthesisRef.current = SpeechSynthesis;

    // Cargar voces - CRÃTICO: En Chrome las voces se cargan async
    let voicesLoaded = false;
    
    const loadVoices = () => {
      const voices = SpeechSynthesis.getVoices();
      if (voices.length > 0 && !voicesLoaded) {
        voicesLoaded = true;
        voicesLoadedRef.current = true;
        console.log('âœ… Voces cargadas:', voices.length);
        
        // Listar voces en espaÃ±ol disponibles
        const spanishVoices = voices.filter(v => v.lang.startsWith('es'));
        console.log('ðŸ‡ªðŸ‡¸ Voces en espaÃ±ol disponibles:', spanishVoices.map(v => `${v.name} (${v.lang})`).join(', '));
      }
    };

    // Intentar cargar voces inmediatamente
    loadVoices();

    // Listener para cuando las voces terminen de cargar (crÃ­tico en Chrome)
    if (SpeechSynthesis.onvoiceschanged !== undefined) {
      SpeechSynthesis.onvoiceschanged = loadVoices;
    }

    // WORKAROUND para Chrome: Forzar carga de voces
    // Chrome necesita que se llame getVoices() al menos una vez
    setTimeout(() => {
      SpeechSynthesis.getVoices();
      loadVoices();
    }, 100);

    // Cleanup
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      if (synthesisRef.current) {
        synthesisRef.current.cancel();
      }
      if (SpeechSynthesis.onvoiceschanged !== undefined) {
        SpeechSynthesis.onvoiceschanged = null;
      }
    };
  }, [onUserSpeech]); // Solo depende de onUserSpeech

  // Iniciar escucha
  const startListening = useCallback(() => {
    if (!recognitionRef.current) {
      setState(prev => ({ ...prev, error: 'Reconocimiento de voz no disponible' }));
      return;
    }

    try {
      // Detener cualquier sÃ­ntesis en curso
      if (synthesisRef.current) {
        synthesisRef.current.cancel();
        setState(prev => ({ ...prev, isSpeaking: false }));
      }

      setState(prev => ({ ...prev, currentTranscript: '', error: null }));
      recognitionRef.current.start();
    } catch (error) {
      console.error('Error iniciando reconocimiento:', error);
      setState(prev => ({ ...prev, error: 'No se pudo iniciar el reconocimiento de voz' }));
    }
  }, []);

  // Detener escucha
  const stopListening = useCallback(() => {
    if (recognitionRef.current && state.isListening) {
      recognitionRef.current.stop();
    }
  }, [state.isListening]);

  // Hablar texto (para respuestas de la IA)
  const speak = useCallback((text: string, options?: {
    rate?: number;
    pitch?: number;
    volume?: number;
    onEnd?: () => void;
  }) => {
    if (!synthesisRef.current) {
      console.warn('Speech Synthesis no disponible');
      return;
    }

    console.log('ðŸ—£ï¸ Iniciando sÃ­ntesis de voz:', text.substring(0, 50) + '...');

    // IMPORTANTE: Cancelar y limpiar COMPLETAMENTE cualquier sÃ­ntesis previa
    if (synthesisRef.current.speaking || synthesisRef.current.pending) {
      console.log('ðŸ›‘ Cancelando sÃ­ntesis previa...');
      synthesisRef.current.cancel();
    }

    // FunciÃ³n para intentar hablar
    const attemptSpeak = (retryCount = 0) => {
      if (!synthesisRef.current) return;

      const voices = synthesisRef.current.getVoices();
      console.log(`ðŸ“‹ Voces disponibles (intento ${retryCount + 1}):`, voices.length);
      
      // Si no hay voces y no hemos reintentado mÃ¡s de 10 veces, esperar
      if (voices.length === 0 && retryCount < 10) {
        console.warn(`âš ï¸ Voces aÃºn no disponibles, reintentando en 500ms... (intento ${retryCount + 1}/10)`);
        setTimeout(() => {
          attemptSpeak(retryCount + 1);
        }, 500);
        return;
      }

      // Si despuÃ©s de 10 intentos no hay voces, proceder de todas formas (usarÃ¡ voz por defecto)
      if (voices.length === 0) {
        console.warn('âš ï¸ No se pudieron cargar voces, usando voz por defecto del sistema');
      }

      // Crear nueva utterance
      const utterance = new SpeechSynthesisUtterance(text);
      currentUtteranceRef.current = utterance;
      
      // Seleccionar mejor voz en espaÃ±ol disponible
      const spanishVoices = voices.filter(v => v.lang.startsWith('es'));
      console.log('ðŸ‡ªðŸ‡¸ Voces en espaÃ±ol encontradas:', spanishVoices.length);
      
      const spanishVoice = voices.find(v => 
        v.lang.startsWith('es-') && (
          v.name.includes('Google') || 
          v.name.includes('Microsoft') ||
          v.name.includes('Paulina') || // macOS
          v.name.includes('Monica') ||  // Windows
          v.name.includes('Diego')      // Google espaÃ±ol
        )
      ) || spanishVoices[0]; // Usar primera voz en espaÃ±ol disponible

      if (spanishVoice) {
        utterance.voice = spanishVoice;
        console.log('ðŸŽ¤ Usando voz:', spanishVoice.name, '- Lang:', spanishVoice.lang);
      } else {
        console.warn('âš ï¸ No se encontrÃ³ voz en espaÃ±ol, usando voz por defecto del sistema');
      }

      // ConfiguraciÃ³n de voz - valores mÃ¡s conservadores para mejor compatibilidad
      utterance.lang = languageRef.current;
      utterance.rate = options?.rate || 1.0;  // Velocidad normal
      utterance.pitch = options?.pitch || 1.0;
      utterance.volume = options?.volume || 1.0;

      // Eventos
      utterance.onstart = () => {
        console.log('âœ… AUDIO COMENZÃ“ A REPRODUCIRSE');
        console.log('ðŸ”Š Hablando:', text.substring(0, 50) + '...');
        setState(prev => ({ ...prev, isSpeaking: true, error: null }));
      };

      utterance.onend = () => {
        console.log('âœ… AUDIO TERMINÃ“ DE REPRODUCIRSE');
        console.log('âœ… SÃ­ntesis completada');
        setState(prev => ({ ...prev, isSpeaking: false }));
        
        if (options?.onEnd) {
          options.onEnd();
        }
        
        // Si autoSpeak estÃ¡ habilitado, reiniciar escucha automÃ¡ticamente
        if (autoSpeakRef.current) {
          setTimeout(() => {
            if (recognitionRef.current) {
              try {
                console.log('ðŸŽ™ï¸ Reactivando micrÃ³fono...');
                setState(prev => ({ ...prev, currentTranscript: '', error: null }));
                recognitionRef.current.start();
              } catch (error) {
                console.error('Error reiniciando reconocimiento:', error);
              }
            }
          }, 500);
        }
      };

      utterance.onerror = (event) => {
        // Errores que podemos ignorar completamente (son "normales" en Chrome/Safari)
        const ignorableErrors = ['canceled', 'interrupted', '', undefined, null, 'unknown'];
        
        if (ignorableErrors.includes(event.error)) {
          // Error vacÃ­o o cancelaciÃ³n - MUY comÃºn en Chrome/Safari
          // NO es un error real, solo un quirk del navegador
          // Solo hacemos log informativo a nivel debug
          console.debug('â„¹ï¸ SpeechSynthesis event:', event.error || 'empty', '(esto es normal en Chrome/Safari)');
          setState(prev => ({ ...prev, isSpeaking: false }));
          
          // Activar micrÃ³fono si autoSpeak estÃ¡ activo
          if (autoSpeakRef.current && options?.onEnd) {
            setTimeout(() => {
              options.onEnd!();
            }, 100);
          }
        } else {
          // Error real (raro pero posible)
          const errorDetails = {
            error: event.error,
            type: event.type,
            message: (event as any).message || 'No message'
          };
          console.error('âŒ Error REAL en sÃ­ntesis (no vacÃ­o):', errorDetails);
          setState(prev => ({ ...prev, isSpeaking: false }));
        }
      };

      // Hablar con try-catch
      try {
        console.log('ðŸ”Š Llamando synthesisRef.current.speak()...');
        console.log('ðŸ“Š Estado de speechSynthesis:', {
          speaking: synthesisRef.current.speaking,
          pending: synthesisRef.current.pending,
          paused: synthesisRef.current.paused
        });
        console.log('ðŸ“ Utterance configurado:', {
          text: utterance.text.substring(0, 50) + '...',
          lang: utterance.lang,
          rate: utterance.rate,
          pitch: utterance.pitch,
          volume: utterance.volume,
          voice: utterance.voice?.name || 'default'
        });
        
        synthesisRef.current.speak(utterance);
        console.log('âœ… speak() llamado exitosamente - esperando evento onstart...');
        
        // Debug: verificar despuÃ©s de 2 segundos si empezÃ³
        setTimeout(() => {
          if (synthesisRef.current) {
            console.log('ðŸ” Estado despuÃ©s de 2s:', {
              speaking: synthesisRef.current.speaking,
              pending: synthesisRef.current.pending,
              paused: synthesisRef.current.paused
            });
            if (!synthesisRef.current.speaking && !synthesisRef.current.pending) {
              console.error('âš ï¸ El audio NO se estÃ¡ reproduciendo despuÃ©s de 2 segundos');
              console.log('ðŸ’¡ Posible causa: permisos de audio bloqueados o voces no cargadas');
            }
          }
        }, 2000);
        
      } catch (error) {
        console.error('ðŸ’¥ ExcepciÃ³n al iniciar sÃ­ntesis:', error);
        setState(prev => ({ ...prev, isSpeaking: false }));
      }
    };

    // Esperar un momento antes de intentar hablar (dar tiempo a cancelaciÃ³n previa)
    setTimeout(attemptSpeak, 100);
    
  }, []); // Sin dependencias externas - todo lo necesario estÃ¡ en refs

  // Detener habla
  const stopSpeaking = useCallback(() => {
    if (synthesisRef.current) {
      synthesisRef.current.cancel();
      setState(prev => ({ ...prev, isSpeaking: false }));
    }
  }, []);

  // Interrumpir (detener habla e iniciar escucha)
  const interrupt = useCallback(() => {
    if (synthesisRef.current) {
      synthesisRef.current.cancel();
      setState(prev => ({ ...prev, isSpeaking: false }));
    }
    
    setTimeout(() => {
      if (recognitionRef.current) {
        try {
          setState(prev => ({ ...prev, currentTranscript: '', error: null }));
          recognitionRef.current.start();
        } catch (error) {
          console.error('Error iniciando reconocimiento:', error);
          setState(prev => ({ ...prev, error: 'No se pudo iniciar el reconocimiento de voz' }));
        }
      }
    }, 200);
  }, []);

  return {
    ...state,
    startListening,
    stopListening,
    speak,
    stopSpeaking,
    interrupt
  };
}


