import { NextRequest, NextResponse } from 'next/server';
import { supabase } from '../../../../lib/supabase/server';

export async function POST(request: NextRequest) {
  console.log('üéôÔ∏è Audio Transcription API - Iniciando transcripci√≥n...');

  try {
    // Verificar autenticaci√≥n
    const authHeader = request.headers.get('authorization');
    if (!authHeader) {
      return NextResponse.json({ error: 'Token de autorizaci√≥n requerido' }, { status: 401 });
    }

    const token = authHeader.replace('Bearer ', '');
    const { data: { user }, error: authError } = await supabase.auth.getUser(token);

    if (authError || !user) {
      console.error('‚ùå Error de autenticaci√≥n:', authError);
      return NextResponse.json({ error: 'No autorizado' }, { status: 401 });
    }

    console.log('üë§ Usuario autenticado:', user.email);

    // Obtener archivo de audio del FormData
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;

    if (!audioFile) {
      return NextResponse.json({ error: 'No se encontr√≥ archivo de audio' }, { status: 400 });
    }

    console.log('üéµ Procesando audio:', {
      name: audioFile.name,
      type: audioFile.type,
      size: audioFile.size
    });

    // Validar tipo de archivo de audio
    const allowedAudioTypes = [
      'audio/webm',
      'audio/wav',
      'audio/mp3',
      'audio/mpeg',
      'audio/ogg',
      'audio/m4a'
    ];

    const isValidAudioType = allowedAudioTypes.some(type => 
      audioFile.type.includes(type.split('/')[1]) || audioFile.type === type
    );

    if (!isValidAudioType) {
      return NextResponse.json({ 
        error: 'Tipo de archivo de audio no soportado. Use WAV, MP3, WebM, OGG, o M4A.' 
      }, { status: 400 });
    }

    // Validar tama√±o (m√°ximo 25MB para audio)
    const maxSize = 25 * 1024 * 1024; // 25MB
    if (audioFile.size > maxSize) {
      return NextResponse.json({ 
        error: 'Archivo de audio muy grande. M√°ximo 25MB permitido.' 
      }, { status: 400 });
    }

    // Validar duraci√≥n m√≠nima (al menos 0.5 segundos de audio)
    if (audioFile.size < 1000) {
      return NextResponse.json({ 
        error: 'Audio muy corto. Graba al menos 1 segundo de audio.' 
      }, { status: 400 });
    }

    let transcription = '';

    try {
      // Intentar transcripci√≥n con diferentes m√©todos
      transcription = await transcribeWithGemini(audioFile);
      
      if (!transcription || transcription.trim().length < 3) {
        // Fallback a transcripci√≥n b√°sica
        transcription = await transcribeWithFallback(audioFile);
      }

      console.log('‚úÖ Transcripci√≥n completada:', {
        length: transcription.length,
        preview: transcription.substring(0, 50) + '...'
      });

      return NextResponse.json({
        success: true,
        transcription: transcription,
        fileName: audioFile.name,
        fileType: audioFile.type,
        fileSize: audioFile.size,
        confidence: transcription.includes('[Transcripci√≥n autom√°tica]') ? 0.7 : 0.9
      });

    } catch (transcriptionError) {
      console.error('‚ùå Error en transcripci√≥n:', transcriptionError);
      
      // Devolver transcripci√≥n de fallback
      const fallbackTranscription = await transcribeWithFallback(audioFile);
      
      return NextResponse.json({
        success: true,
        transcription: fallbackTranscription,
        fileName: audioFile.name,
        fileType: audioFile.type,
        fileSize: audioFile.size,
        confidence: 0.5,
        warning: 'Transcripci√≥n generada con m√©todo de respaldo'
      });
    }

  } catch (error) {
    console.error('‚ùå Error general en transcripci√≥n:', error);
    return NextResponse.json({ 
      error: 'Error interno del servidor durante la transcripci√≥n' 
    }, { status: 500 });
  }
}

// Funci√≥n para transcribir con Google Gemini (implementaci√≥n futura)
async function transcribeWithGemini(audioFile: File): Promise<string> {
  try {
    // Esta ser√≠a la implementaci√≥n con Google Gemini
    // Por ahora, devolvemos un placeholder
    
    const arrayBuffer = await audioFile.arrayBuffer();
    const audioData = new Uint8Array(arrayBuffer);
    
    // Simular procesamiento
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // En una implementaci√≥n real, enviar√≠as el audio a Gemini
    // const geminiResponse = await geminiClient.transcribeAudio(audioData);
    // return geminiResponse.text;
    
    return `[Transcripci√≥n autom√°tica] Este es un mensaje de audio de ${Math.round(audioFile.size / 1024)}KB. Para implementar la transcripci√≥n completa, necesitas configurar la integraci√≥n con Google Gemini o un servicio de speech-to-text.`;
    
  } catch (error) {
    console.error('Error en transcripci√≥n con Gemini:', error);
    throw new Error('Fallo en transcripci√≥n con Gemini');
  }
}

// Funci√≥n de transcripci√≥n de fallback
async function transcribeWithFallback(audioFile: File): Promise<string> {
  try {
    // Informaci√≥n b√°sica del archivo
    const duration = estimateAudioDuration(audioFile.size, audioFile.type);
    
    return `[Nota de voz recibida]

Archivo: ${audioFile.name}
Tama√±o: ${Math.round(audioFile.size / 1024)}KB
Duraci√≥n estimada: ${duration} segundos
Formato: ${audioFile.type}

Para obtener la transcripci√≥n autom√°tica completa, necesitas configurar un servicio de speech-to-text como:
- Google Cloud Speech-to-Text
- OpenAI Whisper
- Amazon Transcribe
- Microsoft Speech Services

Por favor, describe brevemente lo que dijiste en la nota de voz para que FINCO pueda ayudarte mejor.`;
    
  } catch (error) {
    return `[Nota de voz recibida - ${audioFile.name}]

Se recibi√≥ una nota de voz pero no se pudo procesar autom√°ticamente. Por favor, escribe un resumen de lo que dijiste para continuar la conversaci√≥n.`;
  }
}

// Funci√≥n auxiliar para estimar duraci√≥n del audio
function estimateAudioDuration(fileSize: number, mimeType: string): number {
  // Estimaci√≥n muy b√°sica basada en el tama√±o del archivo
  // En una implementaci√≥n real, usar√≠as librer√≠as para obtener la duraci√≥n exacta
  
  let bitrate = 128; // kbps por defecto
  
  if (mimeType.includes('webm')) bitrate = 64;
  else if (mimeType.includes('wav')) bitrate = 256;
  else if (mimeType.includes('mp3')) bitrate = 128;
  else if (mimeType.includes('ogg')) bitrate = 96;
  
  // Duraci√≥n = (tama√±o en bytes * 8) / (bitrate * 1000)
  const durationSeconds = Math.round((fileSize * 8) / (bitrate * 1000));
  
  return Math.max(1, durationSeconds); // M√≠nimo 1 segundo
}

// Funci√≥n para validar formato de audio
function isValidAudioFormat(file: File): boolean {
  const validFormats = [
    'audio/webm',
    'audio/wav',
    'audio/wave',
    'audio/mp3',
    'audio/mpeg',
    'audio/ogg',
    'audio/m4a',
    'audio/aac'
  ];
  
  return validFormats.some(format => 
    file.type === format || 
    file.type.includes(format.split('/')[1])
  );
}

// Funci√≥n para convertir audio a formato compatible (implementaci√≥n futura)
async function convertAudioFormat(audioFile: File, targetFormat: string): Promise<Blob> {
  // Esta funci√≥n podr√≠a usar librer√≠as como ffmpeg.wasm para convertir formatos
  // Por ahora, devolvemos el archivo original
  return audioFile;
} 