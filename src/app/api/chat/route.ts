/**
 * Financial Onboarding Chat API
 *
 * Main API endpoint for MentorIA's 9-question onboarding flow.
 * Handles AI chat, response parsing, profile persistence, caching, and rate limiting.
 *
 * @module api/chat
 */

import { NextRequest, NextResponse } from 'next/server';
import { sendOnboardingMessage, analyzeOnboardingConversation, ChatMessage } from '@/lib/openai/client';
import { createClient } from '@supabase/supabase-js';
import { env, features } from '@/lib/env';
import {
  parseOnboardingResponse,
  logParsingResult,
  ParsedOnboardingData
} from '@/lib/parsers/onboarding-parser';
import { getCachedResponse, setCachedResponse } from '@/lib/cache/gemini-cache';
import {
  checkRateLimit,
  getIdentifier,
  createRateLimitHeaders,
  createRateLimitError,
} from '@/lib/rate-limit';
import { logger } from '@/lib/logger';
import { ChatHistory, ChatRequest } from '../../../types/chat';
import { OnboardingData } from '../../../types/onboarding';

/**
 * POST /api/chat
 *
 * Handles onboarding chat messages with AI-powered financial coaching.
 *
 * Flow:
 * 1. Validates request body (message, chatHistory)
 * 2. Authenticates user (via middleware)
 * 3. Applies rate limiting (10 requests / 10 seconds)
 * 4. Fetches user profile from Supabase
 * 5. Determines question number based on chat history
 * 6. Parses user response to structured data
 * 7. Checks cache for AI response (if enabled)
 * 8. Calls Gemini AI if cache miss
 * 9. Caches successful AI response
 * 10. Persists parsed data to user_profiles table
 * 11. Marks onboarding complete after 9 questions
 * 12. Returns AI response with rate limit headers
 *
 * Rate Limit: 10 requests per 10 seconds per user
 * Cache TTL: 1 hour (if enabled)
 * Auth: Required (enforced by middleware)
 *
 * @param {NextRequest} request - Next.js request with JSON body
 * @returns {Promise<NextResponse>} AI response or error
 *
 * @example Request body:
 * {
 *   "message": "Me llamo Juan P√©rez",
 *   "chatHistory": [{ role: "assistant", content: "¬øC√≥mo te llamas?" }],
 *   "attachments": []
 * }
 *
 * @example Success response (200):
 * {
 *   "message": "¬°Perfecto Juan! ¬øCu√°ntos a√±os tienes?",
 *   "success": true,
 *   "debug": { questionNumber: 2, onboardingCompleted: false } // dev only
 * }
 *
 * @example Rate limit error (429):
 * {
 *   "error": "Demasiadas solicitudes...",
 *   "retryAfter": 10
 * }
 * Headers: X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset
 */
export async function POST(request: NextRequest) {
  try {
    const { message, chatHistory = [], attachments = [] } = await request.json() as ChatRequest;

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensaje es requerido' },
        { status: 400 }
      );
    }

    // Obtener token de autorizaci√≥n del header
    const authHeader = request.headers.get('authorization');
    if (!authHeader) {
      return NextResponse.json(
        { error: 'Token de autorizaci√≥n requerido' },
        { status: 401 }
      );
    }

    const token = authHeader.replace('Bearer ', '');
    
    // Create Supabase client with service role to validate token
    const supabase = createClient(
      env.NEXT_PUBLIC_SUPABASE_URL,
      env.SUPABASE_SERVICE_ROLE_KEY
    );

    // Get authenticated user using the token
    const { data: { user }, error: authError } = await supabase.auth.getUser(token);

    if (authError || !user) {
      console.error('‚ùå Error de autenticaci√≥n:', authError);
      return NextResponse.json(
        { error: 'Usuario no autenticado' },
        { status: 401 }
      );
    }

    // Check rate limit (AI endpoint: 10 requests per 10 seconds)
    const identifier = getIdentifier(user.id, request);
    const rateLimit = await checkRateLimit(identifier, 'AI');

    if (!rateLimit.success) {
      const headers = createRateLimitHeaders(rateLimit);
      return NextResponse.json(
        createRateLimitError(rateLimit),
        {
          status: 429,
          headers,
        }
      );
    }

    // Obtener el perfil del usuario
    const { data: profile, error: profileError } = await supabase
      .from('user_profiles')
      .select('*')
      .eq('user_id', user.id)
      .single() as { data: OnboardingData | null; error: any };

    if (profileError && profileError.code !== 'PGRST116') {
      console.error('Error obteniendo perfil:', profileError);
      // Continuar sin perfil si hay error (excepto si no existe, que es normal)
    }

    // Determinar el n√∫mero de pregunta basado en el historial
    // Contar solo los mensajes del usuario para determinar en qu√© pregunta estamos
    const userMessages = chatHistory.filter((msg) => msg.role === 'user').length;
    const questionNumber = userMessages + 1; // La pr√≥xima pregunta a responder
    
    console.log('ü§ñ Chat API - Usuario:', user.email, 'Pregunta #:', questionNumber, 'Historial:', chatHistory.length, 'Mensajes usuario:', userMessages, 'Mensaje:', message.substring(0, 50) + '...');

    // ‚ö†Ô∏è NOTA: El parseo incremental est√° DESACTIVADO
    // Solo se usa el an√°lisis de IA al final (mensaje 8+)
    // Esto evita que datos parciales incorrectos sobreescriban los datos correctos
    let parsedData: Partial<ParsedOnboardingData> = {};
    // Comentado: No parsear durante la conversaci√≥n
    // if (userMessages > 0 && questionNumber <= 9) {
    //   const currentAnswerQuestion = userMessages;
    //   parsedData = parseOnboardingResponse(currentAnswerQuestion, message);
    //   logParsingResult(currentAnswerQuestion, message, parsedData);
    // }

    // Try to get cached response first (if caching is enabled)
    const cacheContext = {
      questionNumber,
      userMessages,
      historyLength: chatHistory.length,
    };

    let aiMessage: string | null = null;

    if (features.caching) {
      aiMessage = await getCachedResponse(message, cacheContext);
    }

    // If cache miss, call Gemini AI
    let response;
    if (!aiMessage) {
      response = await sendOnboardingMessage(
        message,
        profile || { full_name: user.user_metadata?.full_name, email: user.email },
        chatHistory as ChatMessage[]
      );

      // Cache the successful response
      if (response.success && features.caching) {
        await setCachedResponse(message, response.message, cacheContext);
      }
    } else {
      // Use cached response
      response = {
        success: true,
        message: aiMessage,
      };
    }

    if (!response.success) {
      // En lugar de devolver error 500, devolver el mensaje de error de manera elegante
      return NextResponse.json({
        message: response.message || 'Lo siento, hay un problema temporal. Puedes continuar escribiendo tus respuestas.',
        // Debug info solo en desarrollo (nunca exponer errores internos en producci√≥n)
        ...(env.NODE_ENV === 'development' && {
          debug: {
            questionNumber,
            onboardingCompleted: false,
            error: response.error || 'Error de IA'
          }
        })
      });
    }

    // üéØ Si el onboarding est√° completo (8+ mensajes del usuario), usar IA para analizar TODA la conversaci√≥n
    let finalProfileData: Partial<OnboardingData> = {};
    let onboardingCompleted = false;

    if (userMessages >= 8) {
      console.log('‚úÖ Onboarding completado - Analizando toda la conversaci√≥n con IA...');
      
      try {
        // ü§ñ Usar GPT-4o-mini para analizar toda la conversaci√≥n
        const analysisResult = await analyzeOnboardingConversation(
          chatHistory as ChatMessage[],
          { full_name: profile?.full_name, email: user.email }
        );

        if (analysisResult.success && analysisResult.data) {
          console.log('‚úÖ Datos extra√≠dos por IA:', analysisResult.data);
          
          // Validar civil_status (debe estar en espa√±ol seg√∫n prompt)
          // BD acepta: 'soltero', 'casado', 'divorciado', 'viudo'
          let sanitizedData = { ...analysisResult.data };
          if (sanitizedData.civil_status) {
            const validStatuses = ['soltero', 'casado', 'divorciado', 'viudo'];
            if (!validStatuses.includes(sanitizedData.civil_status)) {
              console.log(`‚ö†Ô∏è civil_status no v√°lido: "${sanitizedData.civil_status}", omitiendo campo`);
              delete sanitizedData.civil_status;
            }
          }
          
          finalProfileData = sanitizedData;
          onboardingCompleted = true;

          // Guardar perfil completo
          const dataToUpdate: Partial<OnboardingData> & { user_id: string } = {
            user_id: user.id,
            ...finalProfileData,
            onboarding_completed: true,
            updated_at: new Date().toISOString()
          };

          const { error: upsertError } = await supabase
            .from('user_profiles')
            .upsert(dataToUpdate, {
              onConflict: 'user_id'
            });

          if (upsertError) {
            console.error('‚ùå Error guardando perfil:', upsertError);
          } else {
            console.log('üéâ Perfil completo guardado exitosamente!');
          }
        } else {
          console.log('‚ö†Ô∏è Error en an√°lisis de IA:', analysisResult.error);
          // Fallback: usar parseo incremental
          finalProfileData = parsedData;
        }
      } catch (analyzeError) {
        console.error('‚ö†Ô∏è Error al analizar onboarding (no cr√≠tico):', analyzeError);
        // Fallback: usar parseo incremental
        finalProfileData = parsedData;
      }
    } else {
      // Durante la conversaci√≥n (mensajes 1-7):
      // NO guardar datos parciales - esperar al an√°lisis final
      // Esto evita datos incorrectos del parseo incremental
      console.log(`üìù Pregunta ${questionNumber}/9 - Continuando conversaci√≥n...`);
    }

    // Add rate limit headers to successful response
    const rateLimitHeaders = createRateLimitHeaders(rateLimit);

    return NextResponse.json(
      {
        message: response.message,
        success: true,
        // Informaci√≥n de progreso (necesaria para el frontend)
        debug: {
          questionNumber,
          onboardingCompleted,
          // Info adicional solo en desarrollo
          ...(env.NODE_ENV === 'development' && {
            profileExists: !!profile,
            userMessages,
            totalMessages: chatHistory.length,
            analyzedWithAI: userMessages >= 8
          })
        }
      },
      {
        headers: rateLimitHeaders,
      }
    );

  } catch (error) {
    console.error('‚ùå Error en chat API:', error);
    return NextResponse.json(
      { error: 'Error interno del servidor' },
      { status: 500 }
    );
  }
} 